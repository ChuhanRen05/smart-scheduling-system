import os
import pandas as pd
import numpy as np
from stable_baselines3 import PPO
from stable_baselines3.common.callbacks import EvalCallback
from stable_baselines3.common.monitor import Monitor 
from tqdm import tqdm
from env_schedule import ScheduleEnv 
from utils import generate_recommendation, score_user_schedule, fill_blank


# ========= Load dataset ==========
# ========= Loading csv ==========
df = pd.read_csv("/Users/nicolesong/smart-scheduling-system/ui/RL/calendar_activity_dataset_1000_rows.csv")
unique_activities = df["Activity Name"].unique().tolist()

# âœ… å¼ºåˆ¶åŠ ä¸Š "None" ç±»å‹ï¼ˆç¡®ä¿ env ä¸­æœ‰å ä½ï¼‰
if "None" not in unique_activities:
    unique_activities.append("None")

activity_map = {name: i for i, name in enumerate(unique_activities)}
df["Activity Code"] = df["Activity Name"].map(activity_map)

# Fill out all other hours for user with default setting
for extra in ["Sleep", "Free"]:
    if extra not in unique_activities:
        unique_activities.append(extra)

activity_map = {name: i for i, name in enumerate(unique_activities)}
df["Activity Code"] = df["Activity Name"].map(activity_map)


# ========= Create env ==========
base_env = ScheduleEnv(df, activity_map)
env = Monitor(base_env)  # wrapped env for training logs

# ========= Load or create model ==========
if os.path.exists("ppo_schedule_model.zip"):
    print("ğŸ“‚ Loading your model: ppo_schedule_model.zip")
    # model = PPO("MlpPolicy", env, verbose=1, tensorboard_log="./logs/tb/")
    model = PPO("MlpPolicy", env, verbose=1)
    
else:
    print("ğŸ†• Creating new PPO model")
    # model = PPO("MlpPolicy", env, verbose=1)
    model = PPO(
    "MlpPolicy",
    env,
    verbose=1,
    ent_coef=0.01,  # å¢åŠ æ¢ç´¢å€¾å‘

)

# ========= EvalCallback ==========
eval_callback = EvalCallback(
    env,
    # best_model_save_path="./logs/",
    log_path="./logs/",
    eval_freq=5000,
    deterministic=True,
    render=False
)

# ========= Train model ==========
# model.learn(total_timesteps=100000, callback=eval_callback, tb_log_name="schedule_run_1")
# model.save("ppo_schedule_model")

for i in tqdm(range(20)):
    model.learn(
        total_timesteps=5000,
        reset_num_timesteps=False,
        callback=eval_callback,
        # tb_log_name="schedule_run_9"
    )
    model.save("ppo_schedule_model")
    print("âœ… Your model is saved as ppo_schedule_model.zip")

# ========= Generate recommended schedule ==========
recommended = generate_recommendation(env, model)
filled_schedule = fill_blank(recommended)  # å¯ä»¥è®¾ä¸º Sleep / Idle / Nap

# === æ‰“å°æ¨èæ—¥ç¨‹ ===
print("\nğŸ“… æ¨èæ—¥ç¨‹ï¼š")
for item in filled_schedule:
    print(f"{item['start']:02d}:00 â†’ {item['activity']} ({item['duration']}h)")


# ========= Score a sample user schedule ==========
user_schedule = [
    {"activity": "Work", "start": 9, "duration": 2},
    {"activity": "Gym Workout", "start": 13, "duration": 1},
    {"activity": "Gaming", "start": 20, "duration": 1},
]


user_score = score_user_schedule(base_env, user_schedule)
print(f"ğŸ§  ç”¨æˆ·ä¸Šä¼ æ—¥ç¨‹å¾—åˆ†ï¼š{user_score}")

